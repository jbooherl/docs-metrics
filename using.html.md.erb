---
breadcrumb: App Metrics Documentation
title: Monitor and troubleshoot apps with App Metrics
owner: App Metrics
list_style_none: true
---

<strong><%= modified_date %></strong>

You can monitor and troubleshoot apps using App Metrics.

## <a id="overview"></a> Understanding the health and performance of your apps

App Metrics helps you understand and troubleshoot the health and performance of your apps by offering the following indicators, data, and
visualizations:

* [Latency](#latency): Response times for your app.
* [Traffic](#traffic): Number of requests made for your app.
* [Errors](#errors): HTTP errors thrown by your app.
* [Saturation (Container Metrics)](#saturation): Three charts measuring CPU, memory, and disk consumption percentages.
* [Custom Metrics](#custom-metrics): User-customizable charts for measuring app performance, such as Spring Boot Actuator and Micrometer metrics, or user-defined custom business metrics.
* [App Events](#events): A chart of update, start, stop, crash, SSH, and staging failure events.
* [Logs](#logs): A list of app logs that you can search, filter, and download.

The following sections describe a standard workflow for App Metrics to monitor or troubleshoot your apps.

## <a id='get-started'></a> Viewing an app

1. In a browser, go to `metrics.sys.DOMAIN` and log in with your User Account and Authentication (UAA) credentials.
2. Select an app from the search bar to view metrics and logs.

App Metrics respects UAA permissions so you can view any app that runs in a space that you have access to.

App Metrics displays app data for a specific time frame on the dashboard.

## <a id="time"></a>Changing the time frame

The charts show time along the horizontal axis.
You can change the time frame for all charts and the logs by using the time selector options. You can select from several preset timescales or select a custom date range.
In addition, from any chart, you can click and drag to zoom in on areas of interest. This adjusts all of the charts, and logs, to show data for that time frame.

## <a id="auto-refresh"></a>Auto refresh the dashboard

Auto refresh mode updates the metrics charts and logs on your dashboard for a timed interval as data is received.

To activate auto refresh, click  **Refresh**  by the time selection options on the dashboard. This action activates live updating of metrics and logs data for your currently selected time frame.

<p class="note"><strong>Note</strong>: The default setting for auto refresh interval is set to one minute and cannot be configured.</p>

## <a id="app-instance"></a>Viewing metrics at the process and app instance level

App Metrics relays metric data at the app process level to allow for an indepth troubleshooting experience, even across a rolling deployment. You are able to view the app metrics that are related to a specific process and focus in further to the specific instances within those processes. This action correlates directly with the processes and app instances in [Apps Manager](https://docs.pivotal.io/application-service/4-0/console/dev-console.html).

By default, the dashboard displays metrics that are aggregated across all processes. To view metrics for a specific process, select a process type from the drop-down menu.

When you select a specific process type, the metrics charts display aggregate data from all instances for the selected process type.

To view metrics for individual instances within the selected process, select the **Instances** radio button on the dashboard.

To view metrics for a specific app instance or selection of specific instances, select your instance or instances from the legend of any chart on the dashboard and select the **Instances** radio button.

## <a id='metrics'></a> Interpreting metrics

The default metrics charts that are included with App Metrics provide high level indicators
for the four golden signals for monitoring the health of apps running on distributed systems:

* Latency
* Traffic
* Errors
* Saturation


The following sections explain how to use each of the charts on the dashboard to monitor and troubleshoot your app.

### <a id='networkMetrics'></a> Network metrics

<p class="note"><strong>Note</strong>: If you do not configure your apps for network traffic, the apps show no data or zeros for the default settings of Latency, Traffic, and Errors metrics.
</p>

* <a id='latency'></a> **Latency**: Average latency of a request in milliseconds. A spike in response time means your users are waiting longer. Scaling app instances can spread that workload over more resources and results in faster response times.

* <a id='traffic'></a> **Traffic**: Number of network requests per minute. A spike in HTTP requests means more users are using your app. Scaling app instances reduces the response time.

* <a id='errors'></a> **Errors**: Number of network request errors per minute. A spike in HTTP errors means one or more 5xx errors occurred. Check your app logs for more information.

### <a id='saturation'></a> Monitor resource saturation with container metrics

The following **Container Metrics** charts are available on the App Metrics dashboard to help monitor resource saturation:

* CPU usage percentage: A spike in CPU might point to a process that is computationally heavy. Scaling app instances relieves the immediate pressure, but you must further investigate the app to better understand and ultimately fix the root cause.

* Memory usage percentage: A consistent, gradual increase in memory might mean a resource leak in the code. Scaling app memory relieves the immediate pressure, but you must find and resolve the underlying issue so that it does not occur again.

* Disk usage percentage: A spike in disk might mean the app is writing logs to files instead of STDOUT, caching data to local disk, or serializing large sessions to disk.

### <a id='events'></a> Correlating metrics to events

 The **Events** chart helps to correlate the metrics to events for your app. They include:

* Crash
* Fail (staging failures)
* Update
* Stop
* Start
* SSH

<p class="note"><strong>Note</strong>: The <b>SSH</b> event corresponds to you successfully using SSH to access a container that runs an instance of the app.</p>

See the following topics for more information about app events:

* [Starting, restarting, and restaging apps](https://docs.pivotal.io/platform/application-service/devguide/deploy-apps/start-restart-restage.html)

* [Troubleshooting app deployment and health](https://docs.pivotal.io/platform/application-service/devguide/deploy-apps/troubleshoot-app-health.html)

## <a id='custom-metrics'></a> Adding custom metric charts

You can add custom metrics charts to your dashboard, including the Spring Boot Actuator and Micrometer metrics. You define the custom metrics that you want to monitor and include them in the Indicator document for your app.

For example, to get custom Actuator, or Micrometer metrics into the Metrics Store, bind Metric Registrar to your app and register your endpoint.

For more information, see [Configuring the Metric Registrar](https://docs.pivotal.io/application-service/4-0/metric-registrar/using.html) and then view these metrics on the App Metrics dashboard.

<p class="note"><strong>Note</strong>: In previous versions, if you encountered an error, in your custom chart creation, the information was not substantial. In this version,
more detailed information appears about the error, and provides you an easier way to troubleshoot.</p>

To view custom metrics, configure your apps to emit those metrics out of the [Loggregator Firehose](https://docs.cloudfoundry.org/loggregator/architecture.html).
In addition, Spring Boot apps with actuators or Micrometer metrics that are implemented emit [these metrics](https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-metrics.html) out of the box, without any changes to the source code.

### <a id='metric-registrar-settings'></a> Configuring Metric Registrar for Spring Metrics

In order for Metric Registrar to accurately report Spring Metrics, the configuration for Metric Registrar must be updated in Tanzu Application Service Tile.

You must remove the  `id` tag from the list of Blocked tags in the Metric Registrar settings for the Tanzu Application Service Tile.

### <a id='create-indicator-doc'></a> Creating an Indicator document

An Indicator document is a YAML document that specifies which app you want to monitor and the indicators you want to use to monitor it.

These are the steps to create an Indicator document:

1. Find the metric you want to monitor.
2. Write the PromQL query.
3. Add the PromQL to your Indicator document.

### Finding the metric name

Verify that the metrics are being emitted.
After you configure Metrics Registrar to scrape your metrics
endpoint, verify your respective endpoint for metric names.

If you use a Prometheus style metrics endpoint, check your app's metrics endpoint at
`app.domain/metrics` and search for the desired metric.

To validate Spring Boot Actuator and Micrometer metrics,
see [Metrics](https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-metrics.html)
in _Spring Boot Actuator: Production-ready Features_ in the Spring Boot documentation.

### Writing a PromQL query

After you have the metric name, write a PromQL query to see the metric:

1. Find additional example PromQL for any of the default charts on the dashboard.
   Click **Info** on any chart or visit the
   [PromQL Query Examples](https://prometheus.io/docs/prometheus/latest/querying/examples/) documentation.

2. Use the PromQL Explorer to test out PromQL before you insert it in the Indicator document:

    1. Click the **+** button on the dashboard.

    2. Test out the queries to see how the graph appears before you place it in the Indicator document.

    <p class="note"><strong>Note</strong>: The PromQL query must have the <code>source_id</code> tag for non-admin users.
    </p>

<p>App Metrics supports using a <code>source_id</code> parameter in the PromQL query which refers to the <code>"$source_id"</code> of the current app.

For example:

```shell
cpu{source_id=“$sourceId”}
```

### Adding PromQL query to your Indicator document

After you have the PromQL query ready, insert it in the Indicator document.

For example, if you have a custom metric `customMetricName500` and want to graph the amount of errors over a one minute
time period, then your PromQL query is:

  ```shell
`sum(avg_over_time(customMetricName500{source_id=\"$sourceId\"}[1m]))`
```

This is an example of the YAML file for an Indicator document:

```console
apiVersion: indicatorprotocol.io/v1
kind: IndicatorDocument

metadata:
  labels:
    deployment: "my deployment name"

spec:
  product:
    name: org,space,app-name
    version: 0.0.1

  indicators:
    - name: CustomErrorCount500
      promql: "sum(rate(customMetricName500{source_id='$sourceId'}[1m]))"
      documentation:
        title: "Custom Metric 500 Errors"
      presentation:
        units: "none"
```

The  `org,space,app-name` in the example determines which app these indicators are applied to.
Replace `org,space,app-name` with the org, space, and app name of the app dashboard that you want to customize.

### <a id="indicator-document-schema"></a> Indicator document schema

App Metrics uses a derivative version of the Indicator Protocol.

## <a id='monitoring'></a> Custom monitoring and alerting

You can add custom monitoring and alerting to your dashboard indicators by creating a monitor document for your app.

### Creating a Monitor document

Monitors are linked to specific indicators, so the first step to adding custom monitoring and alerting to your
app is to verify the names of the indicators you want to monitor.

You can view the indicator names for each chart on your app's dashboard by pointing to the desired chart,
clicking the three vertical dots and selecting **Info**.

The indicator corresponds to one of your custom indicators or to one of the following default indicator names:

* RequestCount
* HttpLatency
* ErrorCount
* CPU
* MemoryPercentage
* DiskPercentage

After you have the indicator names you can create your monitor document that defines the threshold for your indicator
and the webhook to send alerts to.

The following example is an YAML file for an monitor document:

```yaml
product: org,space,app-name

webhook_url: https://my-slack-webhook.com

monitors:
  - name: 500 Errors For Application
    indicator: ErrorCount
    warning:
       operator: gte
       threshold: 1.0
       duration: 1m
       only_every: 1h
    critical:
       operator: gte
       threshold: 2.0
       duration: 1m
       only_every: 15m
```
<p class="note"><strong>Note</strong>: The `org,space,app-name` is responsible for defining which app these indicators are applied to.
Replace this with the org, space, and app name of the app you want to monitor.</p>

Also, `webhook_url`: `https://my-slack-webhook.com` must be where alerts are sent when a threshold is surpassed.

The Slack application is currently the only supported use case, but other webhook platforms might work, if they accept a text payload.

### <a id="monitor-document-schema"></a> Monitor document schema

For more detailed information on the monitor document schema, see [Monitor Document Template Reference](./monitor-document-reference.html).

## <a id="custom-metric-demos"></a> Custom metric demos

View the following videos to enhance your understanding of metric charts:

* [Adding custom application metric charts using Indicator Protocol](https://www.youtube.com/watch?v=KKed-LwJ0BM).
* [Platform-level metric charts to the dashboard](https://www.youtube.com/watch?v=z7CVbYzjxVU).

## <a id="logs"></a>Logs

The **Logs** view displays app log data ingested from the Loggregator Reverse Log Proxy (RLP):

<p class="note"><strong>Note</strong>: Logs with non-UTF-8 characters or non-standard UUID app GUIDs are not stored.</p>

You can interact with the **Logs** view in the following ways:

* **Keyword**: Perform a keyword search. While filtering on keywords, logs results are reduced to only display log lines that contain the matching criteria. Matching terms are also highlighted in blue.
* **Highlight**: Enter a term to visually highlight within your search. The terms are highlighted in orange within the current filter results.
* **Sources**: Choose which sources to display logs from. For more information about logs, see [Log Types and Their Messages](https://docs.vmware.com/en/VMware-Tanzu-Application-Service/4.0/tas-for-vms/deploy-apps-streaming-logs.html).
* **Download**: Download a file containing logs for the current search.
* **Copy**: Click the copy icon to copy the text of the log.

By default, the most recent 1,000 log lines are displayed in the logs drawer. You can click `SHOW 1000 MORE LOGS` to load more.

## <a id="direct-data-access"></a> Direct data access

You can query Metric Store and Log Store directly to access raw data.

### <a id="metric-store-api"></a> Metric Store API

To query Metric Store, consult the documentation for [Using Metric Store](https://docs.vmware.com/en/Metric-Store/1.5/metric-store/GUID-using.html).

### <a id="log-store-api"></a> Log Store API

Make note of the following prerequisites before you query the Log Store:

* [curl](https://github.com/curl/curl)
* [CF Auth Token](https://docs.cloudfoundry.org/cf-cli/install-go-cli.html)

### <a id='authorization-authentication'></a> Authorization and Authentication

When you query the API through HTTPS, each request must have the `Authorization`
header set with a UAA provided token.

### <a id='querying'></a> Querying through HTTP endpoints

**GET** `/v1/sources/{sourceID}/logs`

Issues a query against Log Store data.

**Path Parameters** :

* **sourceID** -- The app or component source ID. App source ID is the same as app GUID.

**Query Parameters**:

* **query** is a [PromQL label selector query](https://prometheus.io/docs/prometheus/latest/querying/basics/#querying-prometheus) for filtering logs on  `message`, `message_type`, `source_type`, and `instance_id`.
  * `message` -- RegEx to search the log message body. Use the backtick operator in case of `\.`.
  * `message_type` -- The file descriptor the log was written to, `OUT` or `ERR`
  * `source_type` -- The source of the log, any subset of `{"API","APP","CELL","HEALTH","LGR","RTR","SSH","STG"}` connected by pipes. For example, `"APP|API"`.
  * `instance_id` -- Filter based on the instance ID of the app or component that wrote the log.

For example:

```json
{
  "metadata": {
    "count": 1,
    "links": {}
  },
  "items": [
    {
      "instance_id": "0",
      "message": "Error: Sample query didn't work",
      "message_type": "OUT",
      "source_id": "50efa176-bd06-42d1-bac8-672aab387e75",
      "source_type": "APP/PROC/WEB",
      "timestamp": "2020-03-24T06:57:29.788299446Z"
    }
  ]
}
```

* **startTime** is an optional UNIX timestamp in nanoseconds or RFC3339. Defaults to 10 minutes ago and must be before end time.
* **endTime** is an optional UNIX timestamp in nanoseconds or RFC3339. Defaults to now and must be after start time.
* **limit** is an optional maximum number of logs to return. Defaults to 100.
* **page** is an optional number of the page of logs to be returned, must be `>= 1`. Defaults to 1.
* **order** is an optional order in which the logs are returned, `asc` or `desc`. Defaults to `desc`.

For example:

```shell
export SYSTEM_DOMAIN="<YOUR_SYSTEM_DOMAIN>"
export SOURCE_ID="$(cf app <YOUR_APP> --guid)"
curl --get -H "Authorization: $(cf oauth-token)" \
     "https://log-store.$YOUR_SYSTEM_DOMAIN/v1/sources/$SOURCE_ID/logs" \
     --data-urlencode 'query={message=~"Error.*"}' \
     --data-urlencode 'startTime=2020-03-24T06:55:00Z' \
     --data-urlencode 'endTime=2020-03-24T06:59:00Z'
```
